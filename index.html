<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AI God</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>
    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      background: rgba(255, 225, 69, 1);
      display: flex;
      justify-content: center;
      align-items: center;
      user-select: none;
      -webkit-user-select: none;
    }

    /* ç¥çš„ç»“æ„ */
    #god {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 50px;  /* è°ƒæ•´é—´è·ï¼Œé€‚é…æ–°çš„ä½ç½® */
    }

    /* çœ¼ç› */
    #eye {
      width: 280px;  /* æ”¾å¤§ä¸€å€ */
      height: 160px;  /* æ”¾å¤§ä¸€å€ */
      background-image: url("./eye.png");
      background-size: contain;
      background-repeat: no-repeat;
      background-position: center;
      pointer-events: none;
      margin-top: -60px;  /* å‘ä¸Šç§»åŠ¨ä¸€ç‚¹ */
    }

    /* å˜´å·´ï¼ˆå½•éŸ³æŒ‰é’®ï¼‰ */
    #mouth {
      width: 160px;
      height: 120px;
      background-image: url("./mouth.png");
      background-size: contain;
      background-repeat: no-repeat;
      background-position: center;
      cursor: pointer;
      transition: transform 0.2s ease, opacity 0.2s ease;
      margin-top: 20px;  /* å‘ä¸‹ç§»åŠ¨ */
    }

    #mouth.recording {
      transform: scale(1.15);
      opacity: 0.8;
    }

    #hint {
      font-size: 14px;
      opacity: 0.6;
    }
  </style>
</head>

<body>

  <div id="god">
    <div id="eye"></div>
    <div id="mouth"></div>
    <div id="hint">Tap mouth to speak</div>
  </div>

<script>
/* =========================
   1. Speech Recognition
========================= */

let stream = null
let recorder = null
let chunks = []
let isRecording = false

const mouth = document.getElementById("mouth")
const hint = document.getElementById("hint")

async function initMic() {
  if (stream) return
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  console.log("ğŸ¤ éº¦å…‹é£å·²åˆå§‹åŒ–")
}

/* =========================
   2. ç‚¹å‡»åˆ‡æ¢å½•éŸ³çŠ¶æ€
========================= */

mouth.addEventListener("click", async () => {
  await initMic()

  if (!isRecording) {
    // â–¶ï¸ å¼€å§‹å½•éŸ³
    chunks = []
    recorder = new MediaRecorder(stream)

    recorder.ondataavailable = (e) => {
      if (e.data.size > 0) chunks.push(e.data)
    }

    recorder.onstop = () => {
      const blob = new Blob(chunks, { type: "audio/webm" })
      console.log("ğŸ›‘ å½•éŸ³ç»“æŸï¼ŒéŸ³é¢‘å¤§å°ï¼š", blob.size)

      // è¿™é‡Œä»¥åæ¥ï¼šå‘ç»™ AI God
      // sendToAI(blob)
    }

    recorder.start()
    isRecording = true
    mouth.classList.add("recording")
    hint.textContent = "Listeningâ€¦ tap again to stop"

    console.log("ğŸ”´ å¼€å§‹å½•éŸ³")
  } else {
    // â¹ åœæ­¢å½•éŸ³
    recorder.stop()
    isRecording = false
    mouth.classList.remove("recording")
    hint.textContent = "Thinkingâ€¦"
    console.log("â¹ åœæ­¢å½•éŸ³")
  }
})
</script>

</body>
</html>
